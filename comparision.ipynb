{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "#Mean Intersection over Union (mIoU)、Dice Coefficient、Precision and Recall:、F1 Score\n",
    "#input: predict_mask, ground_truth_mask (np.array, shape=(H, W)\n",
    "#output mIoU, Dice Coefficient, Precision, Recall, F1 Score\n",
    "\n",
    "\n",
    "# Author: Weijie Zou\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def evaluation(predict, ground_truth, num_classes=3):\n",
    "    IoUs = []\n",
    "    Dice_scores = []\n",
    "    Precisions = []\n",
    "    Recalls = []\n",
    "    F1_scores = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (predict == cls)\n",
    "        gt_cls = (ground_truth == cls)\n",
    "        \n",
    "        intersection = np.logical_and(pred_cls, gt_cls).sum()\n",
    "        union = np.logical_or(pred_cls, gt_cls).sum()\n",
    "        IoU = intersection / union if union != 0 else 0\n",
    "        IoUs.append(IoU)\n",
    "        \n",
    "        Dice = (2 * intersection) / (pred_cls.sum() + gt_cls.sum()) if (pred_cls.sum() + gt_cls.sum()) != 0 else 0\n",
    "        Dice_scores.append(Dice)\n",
    "        \n",
    "        TP = intersection\n",
    "        FP = pred_cls.sum() - TP\n",
    "        FN = gt_cls.sum() - TP\n",
    "        \n",
    "        Precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        Recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        F1 = 2 * (Precision * Recall) / (Precision + Recall) if (Precision + Recall) != 0 else 0\n",
    "        \n",
    "        Precisions.append(Precision)\n",
    "        Recalls.append(Recall)\n",
    "        F1_scores.append(F1)\n",
    "    \n",
    "    mIoU = np.mean(IoUs)\n",
    "    Dice = np.mean(Dice_scores)\n",
    "    Precision = np.mean(Precisions)\n",
    "    Recall = np.mean(Recalls)\n",
    "    F1 = np.mean(F1_scores)\n",
    "    \n",
    "    return mIoU, Dice, Precision, Recall, F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy logic and BP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy logic\n",
    "#MF\n",
    "#MF1 for r   -30~-10 sigmoid \n",
    "def MF1(x):\n",
    "    if x< -30:\n",
    "        return 0\n",
    "    if x> -10:\n",
    "        return 1\n",
    "    return 1/(1+np.exp(-0.1*(x+20)))\n",
    "#MF2 for w  0.2~0.5 sigmoid\n",
    "def MF2(x):\n",
    "    if x< 0.2:\n",
    "        return 0\n",
    "    if x> 0.5:\n",
    "        return 1\n",
    "    return 1/(1+np.exp(-10*(x-0.35)))\n",
    "\n",
    "#MF3 for v -0.23~0.23 \n",
    "def MF3(x):\n",
    "    if x< -0.23:\n",
    "        return 0\n",
    "    if x> 0.23:\n",
    "        return 0\n",
    "    return 1-abs(x)/0.23\n",
    "\n",
    "#MF4 for text_r 0~30 \n",
    "def MF4(x):\n",
    "    if x< 0:\n",
    "        return 0\n",
    "    if x> 30:\n",
    "        return 0\n",
    "    if x<=5:\n",
    "        return x/5\n",
    "    else:\n",
    "        return 1-(x-5)/25 \n",
    "#fuzzy logic   \n",
    "def fuzzy_logic(r, v, w, text_r):\n",
    "    fuzzy_result = np.sum([MF1(r), MF2(w), MF3(v), MF4(text_r)]) / 4\n",
    "    if fuzzy_result < 0.3:\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\Anaconda\\envs\\torch22\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Program\\Anaconda\\envs\\torch22\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#BP\n",
    "# load the model\n",
    "from joblib import dump, load\n",
    "bp = load('model_BP.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from utils.data_vis import plot_img_and_mask, plot_imgs, plot_mask\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data_vis import plot_img_and_mask, plot_imgs, plot_mask,  Visualize_type,Visualize\n",
    "import time  # 导入 time 模块\n",
    "\n",
    "imgs_path = r'F:\\Workspace\\Projects\\气象局技能大赛\\基于机器学习的晴空回波识别\\Data_test\\imgs'\n",
    "masks_path = r'F:\\Workspace\\Projects\\气象局技能大赛\\基于机器学习的晴空回波识别\\Data_test\\masks'\n",
    "\n",
    "files_sv = os.listdir(masks_path)\n",
    "files_sv = [f.split('.')[0] for f in files_sv]\n",
    "\n",
    "ground_truth = []\n",
    "predict_mask_bp = []\n",
    "predict_mask_fuzzy = []\n",
    "total_time_bp = 0\n",
    "total_time_fuzzy = 0\n",
    "\n",
    "for f in files_sv:\n",
    "    img = np.load(os.path.join(imgs_path, f + '.npy'))\n",
    "    r = img[:, :, 0]\n",
    "    v = img[:, :, 1]\n",
    "    w = img[:, :, 2]\n",
    "    ldr = img[:, :, 3]\n",
    "    mask = np.load(os.path.join(masks_path, f + '.npy'))\n",
    "    echo_mask = np.full(mask.shape, np.nan)\n",
    "    echo_mask[r >= -50] = 1  # Clear-air echo\n",
    "    echo_mask[v >= -15] = 1   # Clear-air echo\n",
    "    echo_mask[w >= 0] = 1     # Clear-air echo\n",
    "    echo_mask[mask == 1] += 1  # Meteorological echo\n",
    "    echo_mask[:, 150:][echo_mask[:, 150:] == 1] = 2  #Meteorological echo\n",
    "    mask[echo_mask == 2] = 1  # Adjust mask for Meteorological echo\n",
    "\n",
    "    #plot_imgs(img)\n",
    "    echomask=echo_mask\n",
    "    echomask [np.isnan(echomask)] = 0\n",
    "\n",
    "    start_time_dl = time.time()\n",
    "    echo=echomask.copy()\n",
    "    echo[echo>=1]=1\n",
    "\n",
    "    end_time_dl = time.time()\n",
    "\n",
    "    start_time_feature = time.time()\n",
    "    # Calculate the texture feature\n",
    "    Text_r_m = np.zeros_like(r)\n",
    "    Text_v_m = np.zeros_like(v)\n",
    "    Text_w_m = np.zeros_like(w)\n",
    "    Height = np.arange(r.shape[1]) * 0.03  # Height based on range\n",
    "    for i in range(1, r.shape[0]):\n",
    "        for j in range(1, r.shape[1]):\n",
    "            Text_r_m[i, j] = np.abs(r[i, j] - r[i - 1, j])**2\n",
    "            Text_v_m[i, j] = np.abs(v[i, j] - v[i - 1, j])**2\n",
    "            Text_w_m[i, j] = np.abs(w[i, j] - w[i - 1, j])**2\n",
    "            \n",
    "\n",
    "    Text_r = np.zeros_like(r)\n",
    "    Text_v = np.zeros_like(v)\n",
    "    Text_w = np.zeros_like(w)\n",
    "    H= np.zeros_like(r)\n",
    "    \n",
    "    for i in range(r.shape[0]):\n",
    "        for j in range(r.shape[1]):\n",
    "            i_min = max(i - 2, 0)\n",
    "            i_max = min(i + 2, r.shape[0] - 1)\n",
    "            j_min = max(j - 2, 0)\n",
    "            j_max = min(j + 2, r.shape[1] - 1)\n",
    "            \n",
    "            Text_r[i, j] = np.sum(Text_r_m[i_min:i_max + 1, j_min:j_max + 1]) / ((i_max - i_min + 1) * (j_max - j_min + 1))\n",
    "            Text_v[i, j] = np.sum(Text_v_m[i_min:i_max + 1, j_min:j_max + 1]) / ((i_max - i_min + 1) * (j_max - j_min + 1))\n",
    "            Text_w[i, j] = np.sum(Text_w_m[i_min:i_max + 1, j_min:j_max + 1]) / ((i_max - i_min + 1) * (j_max - j_min + 1))\n",
    "            H[i, j] = Height[j]\n",
    "    end_time_feature = time.time()\n",
    "    total_time_bp += end_time_feature - start_time_feature\n",
    "    total_time_fuzzy += end_time_feature - start_time_feature\n",
    "\n",
    "    echomask_pred_bp = np.zeros_like(echomask)\n",
    "    echomask_pred_fuzzy = np.zeros_like(echomask)\n",
    "    \n",
    "\n",
    "    start_time_bp = time.time()\n",
    "    for i in range(2, r.shape[0] - 2):\n",
    "        for j in range(2, r.shape[1] - 2):\n",
    "            r_ = r[i, j]\n",
    "            v_ = v[i, j]\n",
    "            w_ = w[i, j]\n",
    "            ldr_ = ldr[i, j]\n",
    "            text_r_ = Text_r[i, j]\n",
    "            text_v_ = Text_v[i, j]\n",
    "            text_w_= Text_w[i, j]\n",
    "            h = H[i, j]\n",
    "            data = np.array([r_, v_, w_, ldr_, text_r_, text_v_,text_w_, h]).reshape(1, 8)\n",
    "            data[np.isnan(data)] = -999\n",
    "            if r_ < -50:\n",
    "                echomask_pred_bp[i, j] = 0\n",
    "                \n",
    "            else:\n",
    "                echomask_pred_bp[i, j] = bp.predict(data)[0]\n",
    "    end_time_bp = time.time()\n",
    "    total_time_bp += end_time_bp - start_time_bp\n",
    "\n",
    "    start_time_fuzzy = time.time()\n",
    "    for i in range(2, r.shape[0] - 2):\n",
    "        for j in range(2, r.shape[1] - 2):\n",
    "            r_ = r[i, j]\n",
    "            v_ = v[i, j]\n",
    "            w_ = w[i, j]\n",
    "            ldr_ = ldr[i, j]\n",
    "            text_r_ = Text_r[i, j]\n",
    "            data[np.isnan(data)] = -999\n",
    "            if r_ < -50:\n",
    "                echomask_pred_fuzzy[i, j] = 0\n",
    "            else:\n",
    "                echomask_pred_fuzzy[i, j] = fuzzy_logic(r_, v_, w_, text_r_)\n",
    "    end_time_fuzzy = time.time()\n",
    "    total_time_fuzzy += end_time_fuzzy - start_time_fuzzy\n",
    "\n",
    "    Height=np.array(range(len(r[0])))*0.03\n",
    "    Time=np.array(range(len(r)))\n",
    "    echomask_pred_bp[:,150:][echomask_pred_bp[:,150:]==1]=2\n",
    "    echomask_pred_fuzzy[:,150:][echomask_pred_fuzzy[:,150:]==1]=2\n",
    "    ground_truth.append(echomask)\n",
    "    predict_mask_bp.append(echomask_pred_bp)\n",
    "    predict_mask_fuzzy.append(echomask_pred_fuzzy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for BP:  215.69961500167847\n",
      "Total time for fuzzy logic:  115.10761737823486\n",
      "BP: mIoU:  0.7617916755637565 Dice:  0.8322362421390457 Precision:  0.9037146392112914 Recall:  0.7982138052202433 F1:  0.8322362421390457\n",
      "Fuzzy logic: mIoU:  0.7411400983657757 Dice:  0.821116688703604 Precision:  0.800521367199853 Recall:  0.8666665088609099 F1:  0.8211166887036039\n"
     ]
    }
   ],
   "source": [
    "#flatten\n",
    "predict_mask_bp_list = []\n",
    "predict_mask_fuzzy_list = []\n",
    "ground_truth_list = []\n",
    "for i in range(len(predict_mask_bp)):\n",
    "    predict_mask_bp_list.extend(predict_mask_bp[i].flatten())\n",
    "    predict_mask_fuzzy_list.extend(predict_mask_fuzzy[i].flatten())\n",
    "    ground_truth_list.extend(ground_truth[i].flatten())\n",
    "#to np.array\n",
    "predict_mask_bp_list = np.array(predict_mask_bp_list)\n",
    "predict_mask_fuzzy_list = np.array(predict_mask_fuzzy_list)\n",
    "ground_truth_list = np.array(ground_truth_list)\n",
    "'''predict_mask_bp_list[predict_mask_bp_list==2]=0\n",
    "predict_mask_fuzzy_list[predict_mask_fuzzy_list==2]=0\n",
    "ground_truth_list[ground_truth_list==2]=0'''\n",
    "\n",
    "print('Total time for BP: ', total_time_bp)\n",
    "print('Total time for fuzzy logic: ', total_time_fuzzy)\n",
    "#evaluation\n",
    "mIoU_bp, Dice_bp, Precision_bp, Recall_bp, F1_bp = evaluation(predict_mask_bp_list, ground_truth_list)\n",
    "mIoU_fuzzy, Dice_fuzzy, Precision_fuzzy, Recall_fuzzy, F1_fuzzy = evaluation(predict_mask_fuzzy_list, ground_truth_list)\n",
    "\n",
    "print('BP: mIoU: ', mIoU_bp, 'Dice: ', Dice_bp, 'Precision: ', Precision_bp, 'Recall: ', Recall_bp, 'F1: ', F1_bp)\n",
    "print('Fuzzy logic: mIoU: ', mIoU_fuzzy, 'Dice: ', Dice_fuzzy, 'Precision: ', Precision_fuzzy, 'Recall: ', Recall_fuzzy, 'F1: ', F1_fuzzy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from unet import UNet, UNet2Plus, UNet3Plus, TransUNet, UNetWithSE\n",
    "from utils.dataset import BasicDataset\n",
    "from utils.eval import calculate_iou\n",
    "from utils.data_vis import plot_img_and_mask, plot_imgs, plot_mask, Visualize_type\n",
    "\n",
    "\n",
    "def predict_img(unet_type, net, full_img, device, scale_factor=1, out_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Generate a predicted mask for the given image using a U-Net model.\n",
    "    Args:\n",
    "    - unet_type (str): Type of U-Net model.\n",
    "    - net (torch.nn.Module): The trained U-Net model.\n",
    "    - full_img (np.ndarray): Input image (H, W, C).\n",
    "    - device (torch.device): Computational device (CPU or GPU).\n",
    "    - scale_factor (float): Scale factor for the input image.\n",
    "    - out_threshold (float): Minimum probability threshold for the mask.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Binary mask after thresholding.\n",
    "    \"\"\"\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    img = np.array(full_img, dtype=np.float32)\n",
    "\n",
    "    # Handle NaN and inf values\n",
    "    img[np.isnan(img)] = -99\n",
    "    img[np.isinf(img)] = -99\n",
    "\n",
    "    # Preprocess the image\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(unet_type, img, scale_factor))\n",
    "    img = img.unsqueeze(0).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "        probs = torch.sigmoid(output) if net.n_classes == 1 else F.softmax(output, dim=1)\n",
    "\n",
    "        # Convert prediction to PIL image and resize to original size\n",
    "        probs = probs.squeeze(0)\n",
    "        tf = transforms.Compose([transforms.ToPILImage(), transforms.Resize(full_img.shape[1]), transforms.ToTensor()])\n",
    "        probs = tf(probs.cpu())\n",
    "\n",
    "        # Return thresholded mask\n",
    "        return probs.squeeze().cpu().numpy() > out_threshold\n",
    "\n",
    "\n",
    "def slide_window_predict(unet_type, net, full_img, device, scale_factor=1, out_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict mask for large images using sliding window approach. Divides the image into smaller blocks.\n",
    "    Args:\n",
    "    - unet_type (str): Type of U-Net model.\n",
    "    - net (torch.nn.Module): Trained U-Net model.\n",
    "    - full_img (np.ndarray): Input image (H, W, C).\n",
    "    - device (torch.device): Computational device (CPU or GPU).\n",
    "    - scale_factor (float): Scale factor for the input image.\n",
    "    - out_threshold (float): Minimum probability threshold for the mask.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Binary mask for the entire image.\n",
    "    \"\"\"\n",
    "    windows_size = 400\n",
    "    stride = 80\n",
    "    num_w = (full_img.shape[0] - windows_size) // stride + 1\n",
    "    num_h = 1  # For simplicity, using 1 horizontal window, adjust as needed\n",
    "\n",
    "    count_predict = np.zeros((full_img.shape[0], full_img.shape[1]))\n",
    "    count_overlap = np.zeros((full_img.shape[0], full_img.shape[1]))\n",
    "\n",
    "    for i in range(num_w):\n",
    "        for j in range(num_h):\n",
    "            img = full_img[i * stride:i * stride + windows_size, j * stride:j * stride + windows_size, :]\n",
    "            mask = predict_img(unet_type, net, img, device, scale_factor, out_threshold)\n",
    "\n",
    "            count_predict[i * stride:i * stride + windows_size, j * stride:j * stride + windows_size] += mask\n",
    "            count_overlap[i * stride:i * stride + windows_size, j * stride:j * stride + windows_size] += 1\n",
    "\n",
    "            # Edge handling for the last window\n",
    "            if i == num_w - 1:\n",
    "                img = full_img[full_img.shape[0] - windows_size:, j * stride:j * stride + windows_size, :]\n",
    "                mask = predict_img(unet_type, net, img, device, scale_factor, out_threshold)\n",
    "                count_predict[full_img.shape[0] - windows_size:, j * stride:j * stride + windows_size] += mask\n",
    "                count_overlap[full_img.shape[0] - windows_size:, j * stride:j * stride + windows_size] += 1\n",
    "\n",
    "            if j == num_h - 1 and i == num_w - 1:\n",
    "                img = full_img[full_img.shape[0] - windows_size:, full_img.shape[1] - windows_size:, :]\n",
    "                mask = predict_img(unet_type, net, img, device, scale_factor, out_threshold)\n",
    "                count_predict[full_img.shape[0] - windows_size:, full_img.shape[1] - windows_size:] += mask\n",
    "                count_overlap[full_img.shape[0] - windows_size:, full_img.shape[1] - windows_size:] += 1\n",
    "\n",
    "    # Combine predictions\n",
    "    mask = count_predict / count_overlap\n",
    "    mask = mask > out_threshold\n",
    "\n",
    "    # Post-process the mask\n",
    "    mask[:, 150:][full_img[:, 150:, 0] >= -50] = True\n",
    "    mask[:, 150:][full_img[:, 150:, 1] >= -15] = True\n",
    "    mask[:, 150:][full_img[:, 150:, 2] >= 0] = True\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def predict_met_echo(img,  unet_type, net, device):\n",
    "        \"\"\"\n",
    "        Predict echo mask from radar data (loaded from .npy files) using the trained U-Net model.\n",
    "\n",
    "        - unet_type (str): Type of U-Net model.\n",
    "        - net (torch.nn.Module): Trained U-Net model.\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "        - np.ndarray: Predicted mask.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        img = img\n",
    "\n",
    "        radar_r = img[:, :, 0]\n",
    "        radar_v = img[:, :, 1]\n",
    "        radar_w = img[:, :, 2]\n",
    "        radar_depomask = img[:, :, 3]\n",
    "\n",
    "        # Predict mask based on image size\n",
    "        if img.shape == (400, 400, 4):\n",
    "            mask = predict_img(unet_type, net, img, device)\n",
    "        else:\n",
    "            mask = slide_window_predict(unet_type, net, img, device)\n",
    "\n",
    "        # Post-process the mask\n",
    "        echo_mask = np.full(mask.shape, 0)\n",
    "        echo_mask[radar_r >= -50] = 1\n",
    "        echo_mask[radar_v >= -15] = 1\n",
    "        echo_mask[radar_w >= 0] = 1\n",
    "        echo_mask[mask == 1] += 1\n",
    "        echo_mask[:, 150:][echo_mask[:, 150:] == 1] = 2  # Post-process for higher altitudes\n",
    "\n",
    "\n",
    "        return echo_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet +SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unet_type='se'\n",
    "gpu_id=0\n",
    "if unet_type == 'trans':\n",
    "        net = TransUNet(img_dim=400, in_channels=4, out_channels=128, head_num=4, mlp_dim=512, block_num=8, patch_dim=16, class_num=1)\n",
    "        model = r'model\\TransUnet\\CP_epoch60_miou_0.8984.pth'\n",
    "elif unet_type == 'se':\n",
    "        net = UNetWithSE(n_channels=4, n_classes=1)\n",
    "        model = r'model\\UnetSE_LDR_randomDROP\\CP_epoch60_miou_0.9799.pth'\n",
    "else:\n",
    "        net = UNet(n_channels=4, n_classes=1)\n",
    "        model = r'model\\Unet\\CP_epoch1_miou_tensor(0.9825).pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(model, map_location=device))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85000\\AppData\\Local\\Temp\\ipykernel_36748\\2808364713.py:97: RuntimeWarning: invalid value encountered in divide\n",
      "  mask = count_predict / count_overlap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for deep learning:  5.524238109588623\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from utils.data_vis import plot_img_and_mask, plot_imgs, plot_mask\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data_vis import plot_img_and_mask, plot_imgs, plot_mask,  Visualize_type,Visualize\n",
    "import time \n",
    "\n",
    "imgs_path = r'F:\\Workspace\\Projects\\气象局技能大赛\\基于机器学习的晴空回波识别\\Data_test\\imgs'\n",
    "masks_path = r'F:\\Workspace\\Projects\\气象局技能大赛\\基于机器学习的晴空回波识别\\Data_test\\masks'\n",
    "\n",
    "files_sv = os.listdir(masks_path)\n",
    "files_sv = [f.split('.')[0] for f in files_sv]\n",
    "\n",
    "ground_truth = []\n",
    "predict_mask_dl = []\n",
    "\n",
    "total_time_dl = 0\n",
    "\n",
    "for f in files_sv:\n",
    "    img = np.load(os.path.join(imgs_path, f + '.npy'))\n",
    "    r = img[:, :, 0]\n",
    "    v = img[:, :, 1]\n",
    "    w = img[:, :, 2]\n",
    "    ldr = img[:, :, 3]\n",
    "    img[:, :, 3]=np.full_like(ldr,np.nan)\n",
    "    mask = np.load(os.path.join(masks_path, f + '.npy'))\n",
    "    r=img[:,:,0]\n",
    "    v=img[:,:,1]\n",
    "    w=img[:,:,2]\n",
    "    Height=np.array(range(len(r[0])))*0.03\n",
    "    Time=np.array(range(len(r)))\n",
    "    echomask=np.full(mask.shape,np.nan)\n",
    "    echomask[r >= -50] = 1\n",
    "    echomask[v >=-15] = 1\n",
    "    echomask[w >=0] = 1\n",
    "    echomask[mask==1]+=1\n",
    "    echomask[:,150:][echomask[:,150:]==1]=2\n",
    "    echomask [np.isnan(echomask)] = 0\n",
    "\n",
    "    start_time_dl = time.time()\n",
    "    echomask_dl= np.zeros_like(echomask)\n",
    "    echo=echomask.copy()\n",
    "    echo[echo>=1]=1\n",
    "    echomask_pred_dl=predict_met_echo(img,unet_type, net, device)\n",
    "    '''echo[echomask_pred_dl==1]=2\n",
    "    echomask_pred_dl=echo'''\n",
    "    end_time_dl = time.time()\n",
    "    total_time_dl += end_time_dl - start_time_dl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    echomask_pred_dl[echomask_pred_dl>2]=2\n",
    "\n",
    "    predict_mask_dl.append(echomask_pred_dl)\n",
    "    ground_truth.append(echomask)\n",
    "    \n",
    "print('Total time for deep learning: ', total_time_dl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for Deep Learning:  5.524238109588623\n",
      "Deep Learning: mIoU:  0.968783335023918 Dice:  0.9837854293148531 Precision:  0.9853790100683537 Recall:  0.9822129938806277 F1:  0.983785429314853\n"
     ]
    }
   ],
   "source": [
    "# Flatten the masks\n",
    "predict_mask_dl_list = []\n",
    "ground_truth_list = []\n",
    "for i in range(len(predict_mask_dl)):\n",
    "    predict_mask_dl_list.extend(predict_mask_dl[i].flatten())\n",
    "    ground_truth_list.extend(ground_truth[i].flatten())\n",
    "\n",
    "# Convert to np.array\n",
    "predict_mask_dl_list = np.array(predict_mask_dl_list)\n",
    "ground_truth_list = np.array(ground_truth_list)\n",
    "'''predict_mask_dl_list[predict_mask_dl_list==2]=0\n",
    "ground_truth_list[ground_truth_list==2]=0'''\n",
    "print('Total time for Deep Learning: ', total_time_dl)\n",
    "# Evaluation\n",
    "mIoU_dl, Dice_dl, Precision_dl, Recall_dl, F1_dl = evaluation(predict_mask_dl_list, ground_truth_list)\n",
    "print('Deep Learning: mIoU: ', mIoU_dl, 'Dice: ', Dice_dl, 'Precision: ', Precision_dl, 'Recall: ', Recall_dl, 'F1: ', F1_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
